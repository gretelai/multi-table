{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85baec1b",
   "metadata": {
    "id": "85baec1b"
   },
   "source": [
    "# Synthetics and Multi-Table Relational Databases\n",
    "* This notebook shows how to generate synthetic data directly from a mutli-table relational database\n",
    "* The database used in the example below was first run through this [notebook](https://github.com/gretelai/public_research/blob/main/mutli-table-transforms/RDB_Transforms.ipynb) which is discussed in this [blog](https://gretel.ai/blog/transforms-and-multi-table-relational-databases) where transforms were used to de-identify PII.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bBlvrdCmUZsO",
   "metadata": {
    "id": "bBlvrdCmUZsO"
   },
   "source": [
    "## Capabilities\n",
    "* This notebook can be run on any database SQLAlchemy supports such as Postgresql, SQLite or MySQL\n",
    "* This notebook also contains instructions on how to create synthetic data when the relational tables exist in CSV files.\n",
    "* It is not necessary to first use transforms on your data before using this notebook.\n",
    "* Referential integriety of primary and foreign keys will remain intact\n",
    "* User enters the ratio of synthetic records to original records that they would like produced. For example, 2 means you'd like the synthetic data to be twice the size of the original data. Alternatively, you can \"subset\" the database by using a value less than one. For example, a value of .5 means you'd like the synthetic data to be half the size of the original data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V2z6YkiRWKTL",
   "metadata": {
    "id": "V2z6YkiRWKTL"
   },
   "source": [
    "## Limitations\n",
    "* The primary and foreign keys in your database must be IDs\n",
    "* Keys cannot be composite keys\n",
    "* Cross table field correlations are not maintained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rXzLd2WVXguo",
   "metadata": {
    "id": "rXzLd2WVXguo"
   },
   "source": [
    "## How to use this notebook on your own dataset\n",
    "* Change the database connection string to refer to your database\n",
    "* Alternatively, change the name and location of the CSV files where your data resides\n",
    "* Specify the ratio of synthetic to original records you would like produced\n",
    "* When viewing your data, change the table names used to your own table names\n",
    "* When viewing the synthetic performance report, change the table name used to one of your own table names\n",
    "* Modify the location where you'd like your final synthetic data to be stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd173c",
   "metadata": {
    "id": "f1cd173c"
   },
   "source": [
    "## Our ecommerce database\n",
    "* Execute the below cell to see a diagram of the database we'll be using in this blueprint. The lines in the diagram show connections between primary and foreign keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152cbcb",
   "metadata": {
    "id": "c152cbcb",
    "outputId": "8154b9a0-2dc8-403d-e986-d98b50c1af82"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"https://gretel-blueprints-pub.s3.us-west-2.amazonaws.com/rdb/ecommerce_db.png\",width = 600, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55838e2e",
   "metadata": {
    "id": "55838e2e"
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ea4f8",
   "metadata": {
    "id": "2a6ea4f8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!git clone https://github.com/gretelai/multi-table.git\n",
    "\n",
    "os.chdir('./multi-table')\n",
    "!pip install -U ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b11270",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60b11270",
    "outputId": "77c85daa-bb92-4b10-f473-489b0fb4ebac"
   },
   "outputs": [],
   "source": [
    "# Specify your Gretel API key\n",
    "\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "from gretel_client import configure_session, ClientConfig\n",
    "\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "configure_session(ClientConfig(api_key=getpass(prompt=\"Enter Gretel API key\"), \n",
    "                               endpoint=\"https://api.gretel.cloud\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13217ace",
   "metadata": {
    "id": "13217ace"
   },
   "source": [
    "## Gather data and schema relationships directly from a database\n",
    "* For demonstration purposes, we'll first grab our ecommerce SQLite database from S3\n",
    "* This notebook can be run on any database SQLAlchemy supports such as Postgresql or MySQL\n",
    "* For example, if you have a postgres database, simply swap the `sqlite:///` connection string for a `postgres://` one in the `create_engine` command\n",
    "* Using SQLAlchemy's reflection extension, we will crawl the schema, gather table data and produce a list of relationships by table primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870521d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "870521d9",
    "outputId": "2f1380b7-fd2b-4807-b3eb-65fe7bceb8c8"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import multi_table.rdb_util as rdb\n",
    "\n",
    "!wget https://gretel-blueprints-pub.s3.amazonaws.com/rdb/ecom_xf.db\n",
    "    \n",
    "engine = create_engine(\"sqlite:///ecom_xf.db\")\n",
    "rdb_config = rdb.crawl_db(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c3d77",
   "metadata": {
    "id": "d09c3d77"
   },
   "source": [
    "## Alternatively, specify primary/foreign key relationships and locations of data csv files \n",
    "* This is an alternative to the above four cells that work directly with a database\n",
    "* First, assign `base_path` to the directory where the csv files are located.\n",
    "* Then, add a name/key pair for each table name/filename to `rdb_config[\"table_files\"]`\n",
    "* Add all primary keys for each table to `rdb_config[\"primary_keys\"]`\n",
    "* Add all foreign key/primary keys that connect to the same set under `rdb_config[\"relationships\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1fea42",
   "metadata": {
    "id": "6b1fea42"
   },
   "outputs": [],
   "source": [
    "# base_path is the directory where your csv files can be found\n",
    "base_path = \"https://gretel-blueprints-pub.s3.amazonaws.com/rdb/\"\n",
    "\n",
    "rdb_config = {\n",
    "   \"table_files\": {\n",
    "      \"users\": base_path + \"users_transform.csv\",\n",
    "\n",
    "      \"order_items\": base_path + \"order_items_transform.csv\",\n",
    "       \n",
    "      \"events\": base_path + \"events_transform.csv\",\n",
    "       \n",
    "      \"inventory_items\": base_path + \"inventory_items_transform.csv\",  \n",
    "       \n",
    "      \"products\": base_path + \"products_transform.csv\",\n",
    "       \n",
    "      \"distribution_center\": base_path + \"distribution_center_transform.csv\"\n",
    "   },\n",
    "\n",
    "  # List the primary keys for each table\n",
    "    \n",
    "   \"primary_keys\": {\n",
    "      \"users\": \"id\",\n",
    "\n",
    "      \"order_items\": \"id\",\n",
    "       \n",
    "      \"events\": \"id\",\n",
    "       \n",
    "      \"inventory_items\": \"id\",  \n",
    "       \n",
    "      \"products\": \"id\",\n",
    "       \n",
    "      \"distribution_center\": \"id\"\n",
    "   },\n",
    "\n",
    "  # List the (table, field) relationships between primary and foreign keys \n",
    "   \"relationships\": [\n",
    "          [(\"users\",\"id\"),\n",
    "           (\"order_items\",\"user_id\"),\n",
    "           (\"events\",\"user_id\")\n",
    "          ],         \n",
    "       \n",
    "          [(\"inventory_items\",\"id\"),\n",
    "           (\"order_items\",\"inventory_item_id\")  \n",
    "          ],         \n",
    "\n",
    "          [(\"products\",\"id\"),\n",
    "           (\"inventory_items\",\"product_id\")\n",
    "          ],                \n",
    "\n",
    "          [(\"distribution_center\",\"id\"),\n",
    "           (\"products\",\"distribution_center_id\"),\n",
    "           (\"inventory_items\", \"product_distribution_center_id\")\n",
    "          ]             \n",
    "   ]\n",
    "}\n",
    "\n",
    "# Gather the table data using the filenames entered above\n",
    "\n",
    "rdb_config[\"table_data\"] = {}\n",
    "for table in rdb_config[\"table_files\"]:\n",
    "    filename = rdb_config[\"table_files\"][table]\n",
    "    df = pd.read_csv(filename)\n",
    "    rdb_config[\"table_data\"][table] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e80c0",
   "metadata": {},
   "source": [
    "## Enter the ratio of synthetic records to original records you would like to produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering 1 means the synthetic data will be the same size as the original data\n",
    "# Entering 2 means the synthetic data will be twice the size as the original data\n",
    "# Entering .5 means the synthetic data will be half the size of the original data\n",
    "\n",
    "rdb_config[\"synth_record_size_ratio\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8e247",
   "metadata": {
    "id": "79b8e247"
   },
   "source": [
    "## Take a look at your data by joining two tables\n",
    "* Note that every record in the table \"order_items\" matches to an entry in the table \"users\"\n",
    "* An \"inner\" join will take the intersection of two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893df1c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "893df1c0",
    "outputId": "1cdf5c8d-3599-4171-880b-7977032e7420"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "table1 = \"order_items\"\n",
    "table2 = \"users\"\n",
    "table1_key = \"user_id\"\n",
    "table2_key = \"id\"\n",
    "df1 = rdb_config[\"table_data\"][table1]\n",
    "df2 = rdb_config[\"table_data\"][table2]\n",
    "\n",
    "joined_data = df1.join(df2.set_index(table2_key), how='inner', on=table1_key, lsuffix='_order_items', rsuffix='_users')\n",
    "print(\"Number of records in order_items table is \" + str(len(df1)))\n",
    "print(\"Number of records in user table is \" + str(len(df2)))\n",
    "print(\"Number of records in joined data is \" + str(len(joined_data)))\n",
    "\n",
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243da31",
   "metadata": {
    "id": "c243da31"
   },
   "source": [
    "## Set up the training configs\n",
    "* We'll assign each table the default training config\n",
    "* We'll turn off the similarity privacy filter for the table \"distribution_center\" as it has only 10 training records\n",
    "* Similarly, you can modify the other table configs to match the characteristics of that table (see [here](https://github.com/gretelai/gretel-blueprints/tree/main/config_templates/gretel/synthetics) for example configs that can be used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47218bf",
   "metadata": {
    "id": "b47218bf"
   },
   "outputs": [],
   "source": [
    "# Grab the default Synthetic Config file:\n",
    "from smart_open import open\n",
    "import yaml\n",
    "import copy\n",
    "\n",
    "with open(\"https://raw.githubusercontent.com/gretelai/gretel-blueprints/main/config_templates/gretel/synthetics/default.yml\", 'r') as stream:\n",
    "    default_config = yaml.safe_load(stream)\n",
    "    \n",
    "training_configs = {}\n",
    "for table in rdb_config[\"table_data\"]:\n",
    "    training_configs[table] = copy.deepcopy(default_config)\n",
    "\n",
    "training_configs[\"distribution_center\"]['models'][0]['synthetics']['privacy_filters']['similarity'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d918a",
   "metadata": {},
   "source": [
    "## Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5234060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multi_table.synth_models as sm\n",
    "from gretel_client.projects import create_or_get_unique_project\n",
    "\n",
    "# Designate a project\n",
    "project = create_or_get_unique_project(name=\"rdb-synthetics\")\n",
    "\n",
    "# Synthesize your tables\n",
    "synthetic_tables, errors, models = sm.synthesize_tables(rdb_config, project, training_configs)\n",
    "\n",
    "# Synthesize your primary/foreign keys\n",
    "if errors == False:\n",
    "    synthetic_tables = sm.synthesize_keys(synthetic_tables, rdb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692b7d0",
   "metadata": {
    "id": "0692b7d0"
   },
   "source": [
    "## Verify the size of the new synthetic tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83df8b2",
   "metadata": {
    "id": "f83df8b2",
    "outputId": "434da99f-4315-454e-93b9-207e5839d13e"
   },
   "outputs": [],
   "source": [
    "for table in synthetic_tables:\n",
    "    new_len = len(synthetic_tables[table])\n",
    "    orig_len = len(rdb_config[\"table_data\"][table])\n",
    "    ratio = new_len / orig_len\n",
    "    print(\"Table \" + table + \": Original record count: \" + str(orig_len) + \" New record count: \" + str(new_len) + \" Ratio: \" + str(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09d76e",
   "metadata": {
    "id": "ee09d76e"
   },
   "source": [
    "## View the synthetic data\n",
    "* We'll again join the order_items and users tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "table1 = \"order_items\"\n",
    "table2 = \"users\"\n",
    "table1_key = \"user_id\"\n",
    "table2_key = \"id\"\n",
    "df1 = synthetic_tables[table1]\n",
    "df2 = synthetic_tables[table2]\n",
    "\n",
    "joined_data = df1.join(df2.set_index(table2_key), how='inner', on=table1_key, lsuffix='_order_items', rsuffix='_users')\n",
    "print(\"Number of records in order_items table is \" + str(len(df1)))\n",
    "print(\"Number of records in user table is \" + str(len(df2)))\n",
    "print(\"Number of records in joined data is \" + str(len(joined_data)))\n",
    "\n",
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe611e",
   "metadata": {
    "id": "41fe611e"
   },
   "source": [
    "## View the synthetic performance reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057f4bc",
   "metadata": {
    "id": "a057f4bc",
    "outputId": "6c2e43a2-3b95-45db-a427-9b808f50e115"
   },
   "outputs": [],
   "source": [
    "# Generate report that shows the statistical performance between the training and synthetic data\n",
    "\n",
    "from smart_open import open\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Change table_name to any of the tables in your relational database\n",
    "table_name = \"users\"\n",
    "display(HTML(data=open(models[table_name][\"model\"].get_artifact_link(\"report\")).read(), metadata=dict(isolated=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xVfDsgJoL1mz",
   "metadata": {
    "id": "xVfDsgJoL1mz"
   },
   "source": [
    "## Save the synthetic data back into an SQLite database\n",
    "* Here, we're saving the data into an sqlite database called ecom_synth\n",
    "* To save into a postgres database, use type=\"postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f31da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new data to ecom_synth using the schema in ecom_xf\n",
    "rdb.save_to_rdb(\"ecom_xf\", \"ecom_synth\", synthetic_tables, engine, type=\"sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4302410",
   "metadata": {
    "id": "b4302410"
   },
   "source": [
    "## Alterntively, save the synthetic content into CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dfd622",
   "metadata": {
    "id": "60dfd622"
   },
   "outputs": [],
   "source": [
    "# Change final_dir to be the location where you'd like your csv files saved\n",
    "final_dir = \"./\"\n",
    "for table in synthetic_tables:\n",
    "    df = synthetic_tables[table]\n",
    "    filename = final_dir + table + '_synth.csv'\n",
    "    df.to_csv(filename, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RDB_Synthetics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
